{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data, Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "% matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import textstat\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "#To visualize errors:\n",
    "from prettytable import PrettyTable\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file, test_file = './sampleData/sample_reviews_train.csv', './sampleData/sample_reviews_test.csv'\n",
    "reviews_train = pd.read_csv(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_classification(reviews_df, models, create_vectorizer, num_train=None, num_test=None, weight_fn=None):\n",
    "    \n",
    "    #Turn all the features into useful values:\n",
    "    train_df, test_df = train_test_split(reviews_df, test_size=0.2)\n",
    "    if num_train:\n",
    "        train_df = train_df.sample(num_train)\n",
    "    if num_test:\n",
    "        test_df = test_df.sample(num_test)\n",
    "    vectorizer = create_vectorizer()\n",
    "    vectorizer.fit(train_df)\n",
    "    print('Fit vectorizer')\n",
    "    train_vectors = vectorizer.transform(train_df)\n",
    "    test_vectors = vectorizer.transform(test_df)\n",
    "    print('Created vectors')\n",
    "    \n",
    "    #Create structures to print results of classification nicely:\n",
    "    train_scores, val_scores = defaultdict(list), defaultdict(list)\n",
    "    model_names = [str(model) for model in models]\n",
    "    score_tables = {name: PrettyTable() for name in model_names}\n",
    "    for table in score_tables.values():\n",
    "        table.field_names = ['Data', 'Train F1', 'Validation F1']\n",
    "        \n",
    "    #Here, we need to label each thing as a True or False:\n",
    "    trainLabels = np.ndarray(shape=(train_df.shape[0], 1), dtype=object)\n",
    "    testLabels = np.ndarray(shape=(test_df.shape[0], 1), dtype=object)\n",
    "    \n",
    "    train_vote_count = np.asarray(train_df['total_votes'])\n",
    "    test_vote_count = np.asarray(test_df['total_votes'])\n",
    "    \n",
    "    #For the train data:\n",
    "    falseIndices = np.where(train_vote_count == 0)\n",
    "    trueIndices = np.where(train_vote_count != 0)\n",
    "    \n",
    "    np.put(trainLabels, falseIndices, False)\n",
    "    np.put(trainLabels, trueIndices, True)\n",
    "    \n",
    "    #For the test data:\n",
    "    falseIndices = np.where(test_vote_count == 0)\n",
    "    trueIndices = np.where(test_vote_count != 0)\n",
    "    \n",
    "    np.put(testLabels, falseIndices, False)\n",
    "    np.put(testLabels, trueIndices, True)\n",
    "    \n",
    "    #To prevent unknown type errors:\n",
    "    trainLabels = trainLabels.astype(bool)\n",
    "    testLabels = testLabels.astype(bool)\n",
    "    \n",
    "    #Now we do the classification:\n",
    "    #Note that the flatten() was added just to avoid an annoying warning about column vectors\n",
    "    for model in models:\n",
    "        if (model == LinearSVC):\n",
    "            createdModel = model(max_iter=10000)\n",
    "        else:\n",
    "            createdModel = model()\n",
    "        if weight_fn:\n",
    "            createdModel.fit(train_vectors, trainLabels.flatten(), sample_weight=weight_fn(train_df))\n",
    "        else:\n",
    "            createdModel.fit(train_vectors, trainLabels.flatten())\n",
    "        print('Fit model')\n",
    "    \n",
    "        #Get error stats:\n",
    "        #First the predictions:\n",
    "        train_predictions = createdModel.predict(train_vectors)\n",
    "        test_predictions = createdModel.predict(test_vectors)\n",
    "\n",
    "        #Now the actual scores:\n",
    "        train_f1 = f1_score(trainLabels, train_predictions, pos_label=True)\n",
    "        val_f1 = f1_score(testLabels, test_predictions, pos_label=False)\n",
    "\n",
    "        #Now build the tables:\n",
    "        #name = model.__class__.__name__\n",
    "        name = str(model)\n",
    "        score_tables[name].add_row(['Placeholder', f'{train_f1:.3f}', f'{val_f1:.3f}'])\n",
    "        train_scores[name].append(train_f1)\n",
    "        val_scores[name].append(val_f1)\n",
    "\n",
    "    #Give a more general metric:\n",
    "    for name, table in score_tables.items():\n",
    "        table.add_row(\n",
    "            ('Average +/- std.dev',\n",
    "             f'{np.mean(train_scores[name]):.3f} +/- {np.std(train_scores[name]):.3f}', \n",
    "             f'{np.mean(val_scores[name]):.3f} +/- {np.std(val_scores[name]):.3f}'\n",
    "            ))\n",
    "    for name, table in score_tables.items():\n",
    "        print(f\"\\n{name}\\n{'-' * len(name)}\")\n",
    "        print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PandasCountVectorizer(TransformerMixin):\n",
    "    # A bag-of-words vectorizer that works with an entire DataFrame as input.\n",
    "    # This lets me create a combined feature pipeline with multiple feature vectorizers\n",
    "    # where I don't have to worry about passing different columns to each.\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.vectorizer = CountVectorizer(*args, **kwargs)\n",
    "\n",
    "    def fit(self, X, *args, **kwargs):\n",
    "        self.vectorizer.fit(X['text'].values)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.vectorizer.transform(X['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomFeatures(TransformerMixin):\n",
    "    # A feature vectorizer that creates features based on length, readability and review stars.\n",
    "    # Use this to add other new custom features (like sentiment and user history maybe)\n",
    "    # Btw, I think sentiment might not help much - intuitively it seems like it'd be highly correlated with \n",
    "    # review stars - 5 star rating - likely positive; 1 star rating - likely negative.\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    def _review_features(self, review):\n",
    "        return [\n",
    "            len(review.text),\n",
    "            review.stars,\n",
    "            review.coleman_liau_index,\n",
    "            review.automated_readability_index,\n",
    "            review.dale_chall_readability_score,\n",
    "            review.linsear_write_formula,\n",
    "            review.gunning_fog,\n",
    "            review.flesch_reading_ease,\n",
    "        ]\n",
    "\n",
    "    def transform(self, reviews):\n",
    "        return np.array([self._review_features(r) for r in reviews.itertuples()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit vectorizer\n",
      "Created vectors\n",
      "Fit model\n",
      "Fit model\n",
      "Fit model\n",
      "Fit model\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "--------------------------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.983      |      0.644      |\n",
      "| Average +/- std.dev | 0.983 +/- 0.000 | 0.644 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n",
      "\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "----------------------------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.607      |      0.680      |\n",
      "| Average +/- std.dev | 0.607 +/- 0.000 | 0.680 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n",
      "\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "---------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.604      |      0.680      |\n",
      "| Average +/- std.dev | 0.604 +/- 0.000 | 0.680 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n",
      "\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "---------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.599      |      0.685      |\n",
      "| Average +/- std.dev | 0.599 +/- 0.000 | 0.685 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordinary Classification with bag of words with basic filtering\n",
    "bow_vectorizer_fn = lambda: PandasCountVectorizer(min_df=10, max_df=0.75, max_features=1000)\n",
    "\n",
    "#Now we classify with each model:\n",
    "models = [RandomForestClassifier, LogisticRegression, XGBClassifier, LinearSVC]\n",
    "run_classification(reviews_train, models, bow_vectorizer_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See here for how I'm calculating baseline F1: https://stats.stackexchange.com/questions/217376/intuition-about-f1-score\n",
    "\n",
    "So first let's get some metrics/methodology descriptions out of the way: I went with Munmun's suggestion of just predict class based on whether any votes were given to a review. This avoids the whole threshold issue and actually gives about a 40/60 split on the data (40% is classified as \"endorsed\" or \"True\" in the case of the above code). For baseline metrics, we can achieve a 0.65 F1 score on the train set and 0.651 F1 score on the validation set, should we predict all reviews to have social endorsement.\n",
    "\n",
    "Taking those values into consideration, the models we are trying do not do very well. The Random Forest seems to overfit to the training data, as it gets a 0.985 F1 score and a 0.65 F1 score on the validation set, so it did very badly. LogisticRegression gets a validation F1 score of 0.68, which sounds better than the forest, until you realize that its training F1 score is 0.61, so that's actually worse than the F1 baseline. It's a similar story with the XGB Classifier, and SVC is having problems, so...\n",
    "\n",
    "In any case, the bag of words feature alone does not help and can actually make things worse. It does not bode well for classification unfortunately, but let's keep going and see what we get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add readability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coleman_liau_index\n",
      "automated_readability_index\n",
      "dale_chall_readability_score\n",
      "linsear_write_formula\n",
      "gunning_fog\n",
      "flesch_reading_ease\n"
     ]
    }
   ],
   "source": [
    "readability_fns = [\n",
    "    textstat.coleman_liau_index,\n",
    "    textstat.automated_readability_index,\n",
    "    textstat.dale_chall_readability_score,\n",
    "    textstat.linsear_write_formula,\n",
    "    textstat.gunning_fog,\n",
    "    textstat.flesch_reading_ease,\n",
    "]\n",
    "for fn in readability_fns:\n",
    "    print(fn.__name__)\n",
    "    reviews_train[fn.__name__] = reviews_train['text'].apply(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_train.to_csv(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit vectorizer\n",
      "Created vectors\n",
      "Fit model\n",
      "Fit model\n",
      "Fit model\n",
      "Fit model\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "--------------------------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.983      |      0.659      |\n",
      "| Average +/- std.dev | 0.983 +/- 0.000 | 0.659 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n",
      "\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "----------------------------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.614      |      0.687      |\n",
      "| Average +/- std.dev | 0.614 +/- 0.000 | 0.687 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n",
      "\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "---------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.628      |      0.680      |\n",
      "| Average +/- std.dev | 0.628 +/- 0.000 | 0.680 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n",
      "\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "---------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.286      |      0.683      |\n",
      "| Average +/- std.dev | 0.286 +/- 0.000 | 0.683 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification with bag-of-words + custom features (length, review stars, different readability scores)\n",
    "bow_readability_vectorizer_fn = lambda: FeatureUnion([\n",
    "    ('bow', PandasCountVectorizer(min_df=10, max_df=0.75, max_features=1000)),\n",
    "    ('custom', CustomFeatures()),\n",
    "])\n",
    "run_classification(reviews_train, models, bow_readability_vectorizer_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the logistic regression seemed to get some benefit out of adding these features, but that still didn't really give us much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I tried weighted classification - since we have lots of data with near-zero votes and very few with high votes, I decided to add a weight to each training example proportional to its vote count. I experimented with different formulae - nothing helps much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit vectorizer\n",
      "Created vectors\n",
      "Fit model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model\n",
      "Fit model\n",
      "Fit model\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "--------------------------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.982      |      0.658      |\n",
      "| Average +/- std.dev | 0.982 +/- 0.000 | 0.658 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n",
      "\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "----------------------------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.649      |      0.648      |\n",
      "| Average +/- std.dev | 0.649 +/- 0.000 | 0.648 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n",
      "\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "---------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.659      |      0.636      |\n",
      "| Average +/- std.dev | 0.659 +/- 0.000 | 0.636 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n",
      "\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "---------------------------------------\n",
      "+---------------------+-----------------+-----------------+\n",
      "|         Data        |     Train F1    |  Validation F1  |\n",
      "+---------------------+-----------------+-----------------+\n",
      "|     Placeholder     |      0.459      |      0.704      |\n",
      "| Average +/- std.dev | 0.459 +/- 0.000 | 0.704 +/- 0.000 |\n",
      "+---------------------+-----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "weight_by_votes = lambda df: 1 + df.total_votes.values/10\n",
    "run_classification(reviews_train, models, bow_readability_vectorizer_fn, weight_fn=weight_by_votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighting certain samples somehow made things worse, and I'm not sure what that really means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
